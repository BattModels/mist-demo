train::
  data: PropertyPredictionDataModule
  data.batch_size: 128
  data.path: /home/anoushkab/molformer_ft
  data.tokenizer: ibm/MoLFormer-XL-both-10pct
  data.dataset_name: bace
  data.num_workers: 1
  data.task_specs: 
    - measure_name: "Class"
      n_classes: 2
  model: LMFinetuning
  model.encoder_class: RoBERTa
  model.pretrained_checkpoint: /home/anoushkab/electrolyte_fm/mist/azua0s4s/checkpoints/epoch=0-step=10394.ckpt
  model.optimizer: torch.optim.Adam
  model.optimizer.lr: 1.6e-4
  model.optimizer.weight_decay: 0.01
  model.lr_schedule: electrolyte_fm.utils.lr_schedule.RelativeCosineWarmup
  model.lr_schedule.num_training_steps: 250000
  model.lr_schedule.num_warmup_steps: beta2
  model.lr_schedule.rel_decay: 0.1