train::
  data: RobertaDataSet
  data.path: /home/awadell/realspace_v3_dev/
  data.num_workers: 1  # Only have one shard per GPU in realspace_v2_dev\
  data.batch_size: 128
  data.tokenizer: ibm/MoLFormer-XL-both-10pct
  model: RoBERTa
  model.optimizer: torch.optim.Adam
  model.optimizer.lr: 1.6e-4
  model.optimizer.weight_decay: 0.01
  model.lr_schedule: electrolyte_fm.utils.lr_schedule.RelativeCosineWarmup
  model.lr_schedule.num_training_steps: 250000
  model.lr_schedule.num_warmup_steps: beta2
  model.lr_schedule.rel_decay: 0.1
