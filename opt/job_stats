#!/usr/bin/env python
import typer
import subprocess
import statistics
import json
from pathlib import Path
from typing_extensions import Annotated

cli = typer.Typer()


def get_nvtx_range(filter: str, file: Path, unit: str = "ns", min_time=1e6):
    assert file.is_file()
    out = subprocess.Popen(
        [
            "nsys",
            "stats",
            "--report",
            "nvtx_sum",
            "--timeunit",
            unit,
            "--format",
            "csv",
            str(file.resolve()),
        ],
        stdout=subprocess.PIPE,
        encoding="utf-8",
    )
    times = []
    while row := out.stdout.readline():
        if "," not in row:
            continue
        data = row.split(",")
        if filter in data[9]:
            times.append(float(data[1]))

        # stop once total time is less than min_time
        try:
            if float(data[1]) <= min_time:
                break
        except ValueError:
            pass  # ignore, likely header line

    return times


@cli.command()
def train(
    files: list[Path],
    unit: Annotated[
        str, typer.Option(help="Time unit for nsys report")
    ] = "milliseconds",
    min_time: Annotated[
        float, typer.Option(help="Minimum Total Time for a nvtx range to be considered")
    ] = 1,
):
    """Report batch throughput statistics from nsys reports"""
    range("run_training_batch", files, min_time=min_time, unit=unit)


@cli.command()
def range(
    range: str,
    files: Annotated[list[Path], typer.Argument(help="nsys reports to process")],
    unit: Annotated[
        str, typer.Option(help="Time unit for nsys report")
    ] = "milliseconds",
    min_time: Annotated[
        float, typer.Option(help="Minimum Total Time for a nvtx range to be considered")
    ] = 1,
):
    times = []
    for file in files:
        times.extend(
            get_nvtx_range(range, file, unit, min_time=min_time)[1:]
        )  # Drop the first batches runtime

    stats = {
        "times": times,
        "median": statistics.median(times),
        "mean": statistics.mean(times),
        "min": min(times),
        "max": max(times),
        "stddev": statistics.stdev(times),
        "count": len(times),
        "unit": unit,
        "n_files": len(files),
    }
    print(json.dumps(stats))


if __name__ == "__main__":
    cli()
